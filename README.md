# ğŸ§  DINOv3 + ViT-Adapter + Mask2Former

> Semantic segmentation on LoveDA using a frozen DINOv3-ViT-L/16 backbone with a trainable ViT-Adapter and Mask2Former head.

## ğŸ¯ What This Project Does

Combines three powerful components for satellite image segmentation:

| Component | Role | Trainable? |
|-----------|------|------------|
| **DINOv3-ViT-L/16** | Feature extraction backbone (~1B params) | â„ï¸ Frozen |
| **ViT-Adapter** | Converts single-scale ViT â†’ multi-scale FPN (~50M params) | âœ… Yes |
| **Mask2Former** | Universal segmentation head | âœ… Yes |

**Dataset:** [LoveDA](https://github.com/Junjue-Wang/LoveDA) â€” 7-class land-use segmentation (building, road, water, barren, forest, agriculture, background)

---

## ğŸš€ Quick Start

```bash
# 1. Install dependencies
pip install -r requirements_hydra.txt

# 2. Set HuggingFace token
source env.sh

# 3. Train! (720Ã—720, 50 epochs)
python train_hydra.py

# 4. Quick test (1 epoch)
python train_hydra.py training=quick_test

# 5. Evaluate a checkpoint
python evaluate_hydra.py checkpoint_path=runs/<your_run>/checkpoints/best.ckpt
```

---

## ğŸ—ï¸ Architecture

```
Input Image (720Ã—720)
     â”‚
     â–¼
DINOv3-ViT-L/16 (frozen)  â”€â”€â†’  Features at layers [4, 11, 17, 23]
     â”‚
     â–¼
ViT-Adapter (trainable)   â”€â”€â†’  Multi-scale FPN: H/4, H/8, H/16, H/32
     â”‚
     â–¼
Mask2Former Head           â”€â”€â†’  7-class segmentation map
```

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ train_hydra.py              ğŸ‹ï¸ Training script (PyTorch Lightning + Hydra)
â”œâ”€â”€ evaluate_hydra.py           ğŸ“Š Evaluation script
â”œâ”€â”€ data.py                     ğŸ“¦ LoveDA dataset & dataloaders
â”œâ”€â”€ dinov3_mask2former_integration.py   ğŸ§  Model builder (DINOv3)
â”œâ”€â”€ dinov2_mask2former_integration.py   ğŸ§  Model builder (DINOv2 alt)
â”œâ”€â”€ env.sh                      ğŸ”‘ Environment secrets (gitignored)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ backbone/dinov3_adapter.py      ğŸ”§ ViT-Adapter implementation
â”‚   â””â”€â”€ utils/ms_deform_attn.py         ğŸ”§ Deformable attention
â”œâ”€â”€ conf/                       âš™ï¸ Hydra configs
â”‚   â”œâ”€â”€ config.yaml             Main config (720Ã—720)
â”‚   â”œâ”€â”€ model/                  Model config
â”‚   â”œâ”€â”€ data/                   Dataset configs (720, 1024)
â”‚   â”œâ”€â”€ training/               Training configs (default, quick_test)
â”‚   â””â”€â”€ logging/                Logging & checkpoint config
â””â”€â”€ docs/                       ğŸ“– Documentation
    â”œâ”€â”€ ARCHITECTURE.md         Model architecture deep-dive
    â”œâ”€â”€ TRAINING.md             Training guide & usage
    â”œâ”€â”€ DATA.md                 Dataset & data pipeline
    â”œâ”€â”€ CONFIGURATION.md        Hydra config reference
    â”œâ”€â”€ RESULTS.md              Training results & analysis
    â””â”€â”€ FILE_MAP.md             Complete file reference
```

---

## ğŸ“Š Results So Far

| Model | Epochs | mIoU (semantic) | Best Classes |
|-------|--------|-----------------|--------------|
| DINOv2-ViT-B/14 | 48 | 0.271 | Agriculture (0.50), Building (0.50) |
| DINOv3-ViT-L/16 | early | 0.118 | In progress... |

See [docs/RESULTS.md](docs/RESULTS.md) for full breakdown.

---

## ğŸ“– Documentation

| Doc | What's Inside |
|-----|---------------|
| [Architecture](docs/ARCHITECTURE.md) | ğŸ—ï¸ Full model architecture, components, parameter counts |
| [Training](docs/TRAINING.md) | ğŸ‹ï¸ How to train, hyperparameters, troubleshooting |
| [Data](docs/DATA.md) | ğŸ“¦ LoveDA dataset, classes, preprocessing pipeline |
| [Configuration](docs/CONFIGURATION.md) | âš™ï¸ All Hydra config options + CLI overrides |
| [Results](docs/RESULTS.md) | ğŸ“Š Training metrics, per-class analysis, improvements |
| [File Map](docs/FILE_MAP.md) | ğŸ—‚ï¸ Every file and what it does |

---

## ğŸ› ï¸ Common Commands

```bash
# Train with defaults
python train_hydra.py

# Quick test (1 epoch)
python train_hydra.py training=quick_test

# High-resolution (1024Ã—1024)
python train_hydra.py --config-name=config_1024

# Custom params
python train_hydra.py training.max_epochs=100 training.learning_rate=1e-4 data.batch_size=4

# View TensorBoard
tensorboard --logdir logs/

# View resolved config
python train_hydra.py --cfg job
```
