# ğŸ—‚ï¸ File Map â€” Quick Reference

> Every file in this project and what it does. Use this to orient yourself fast.

## ğŸ“ Project Root

| File | Purpose |
|------|---------|
| `train_hydra.py` | ğŸ‹ï¸ **Main training script** â€” PyTorch Lightning + Hydra. Trains the model on LoveDA |
| `evaluate_hydra.py` | ğŸ“Š **Evaluation script** â€” Loads checkpoint, runs validation, outputs metrics |
| `data.py` | ğŸ“¦ **Dataset & DataLoaders** â€” `LoveDADataset` class + `create_dataloaders()` factory |
| `dinov3_mask2former_integration.py` | ğŸ§  **DINOv3 model builder** â€” Creates integrated DINOv3 + Adapter + Mask2Former model |
| `dinov2_mask2former_integration.py` | ğŸ§  **DINOv2 model builder** â€” Alternative using DINOv2-ViT-B/14 backbone |
| `env.sh` | ğŸ”‘ **Environment secrets** â€” HuggingFace token (gitignored) |
| `requirements_hydra.txt` | ğŸ“‹ **Dependencies** â€” All pip packages needed |
| `training_results.json` | ğŸ“ˆ **Training output** â€” Best metrics from DINOv3 training |
| `__init__.py` | ğŸ“¦ Package init (empty) |

## ğŸ“ `models/` â€” Model Architecture

| File | Purpose |
|------|---------|
| `models/backbone/dinov3_adapter.py` | ğŸ”§ **Core adapter** â€” `DINOv3_Adapter` class: converts single-scale ViT â†’ multi-scale FPN |
| `models/utils/ms_deform_attn.py` | ğŸ”§ **Deformable attention** â€” `MSDeformAttn` module for efficient multi-scale attention |
| `models/utils/ops/` | âš¡ **CUDA ops** â€” Optional compiled C++/CUDA kernels for faster deformable attention |

## ğŸ“ `conf/` â€” Hydra Configuration

| File | Purpose |
|------|---------|
| `conf/config.yaml` | âš™ï¸ **Main config** â€” Composes all sub-configs (720Ã—720 default) |
| `conf/config_1024.yaml` | âš™ï¸ **High-res config** â€” Same but with 1024Ã—1024 images |
| `conf/model/dinov3_mask2former.yaml` | âš™ï¸ **Model config** â€” Backbone name, interaction indexes, num_classes |
| `conf/data/loveda.yaml` | âš™ï¸ **Data config (720)** â€” Dataset paths, batch size, class names/colors |
| `conf/data/loveda_1024.yaml` | âš™ï¸ **Data config (1024)** â€” Same but 1024Ã—1024 |
| `conf/training/default.yaml` | âš™ï¸ **Training config** â€” Epochs, LR, optimizer, scheduler |
| `conf/training/quick_test.yaml` | âš™ï¸ **Quick test config** â€” 1 epoch for debugging |
| `conf/logging/default.yaml` | âš™ï¸ **Logging config** â€” TensorBoard, CSV, checkpointing |

## ğŸ“ `evaluation_results/` â€” Past Evaluation Outputs

| File | Purpose |
|------|---------|
| `evaluation_results/evaluation_summary.txt` | ğŸ“Š Overall metrics (mIoU, accuracy, F1) from DINOv2 eval |
| `evaluation_results/classification_report.txt` | ğŸ“Š Per-class precision, recall, F1, IoU |
| `evaluation_results/confusion_matrix.png` | ğŸ“Š Confusion matrix visualization |
| `evaluation_results/prediction_samples.png` | ğŸ“Š Sample prediction visualizations |

## ğŸ“ `logs/` â€” Training Logs

| Directory | Purpose |
|-----------|---------|
| `logs/dinov3_mask2former_loveda/` | ğŸ“ˆ TensorBoard logs (DINOv3 runs) |
| `logs/dinov3_mask2former_loveda_csv/` | ğŸ“ˆ CSV metric logs (DINOv3 runs) |
| `logs/dinov2_mask2former_loveda/` | ğŸ“ˆ TensorBoard logs (DINOv2 runs) |

## ğŸ“ `docs/` â€” Documentation

| File | Purpose |
|------|---------|
| `docs/ARCHITECTURE.md` | ğŸ—ï¸ Model architecture deep-dive |
| `docs/TRAINING.md` | ğŸ‹ï¸ Training pipeline & usage guide |
| `docs/DATA.md` | ğŸ“¦ Dataset & data loading docs |
| `docs/CONFIGURATION.md` | âš™ï¸ Hydra config reference |
| `docs/RESULTS.md` | ğŸ“Š Training/evaluation results & analysis |
| `docs/FILE_MAP.md` | ğŸ—‚ï¸ This file |
