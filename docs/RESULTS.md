# ğŸ“Š Training & Evaluation Results

> Summary of all training runs and their outcomes

---

## ğŸ§ª Run 1: DINOv3-ViT-L/16 (Early Training)

**Source:** `training_results.json`

| Property | Value |
|----------|-------|
| Model | DINOv3-ViT-L/16 + Mask2Former |
| Dataset | LoveDA |
| Image size | 720Ã—720 |
| Batch size | 8 |
| Interaction indexes | [4, 11, 17, 23] |
| Patches | 45Ã—45 = 2,025 per image (+ 5 special tokens) |

### Metrics
| Metric | Value |
|--------|-------|
| **Best val mIoU (semantic)** | **0.1175** |
| Note | Excluding background, early training |

> âš ï¸ This appears to be from an early/incomplete training run. More epochs needed.

---

## ğŸ§ª Run 2: DINOv2-ViT-B/14 (Full Training â€” 48 epochs)

**Source:** `evaluation_results/`

| Property | Value |
|----------|-------|
| Model | DINOv2-ViT-B/14 + Mask2Former |
| Checkpoint | `dinov2-mask2former-loveda-epoch=48-val_mean_iou=0.29.ckpt` |
| Dataset | LoveDA Val split |
| Total pixels evaluated | 33,541,919 |

### Overall Metrics

| Metric | Value |
|--------|-------|
| **Mean IoU (all classes)** | **0.2711** |
| Accuracy | 0.4350 |
| F1-Score (macro) | 0.3934 |
| Weighted accuracy | 0.5700 |

### Per-Class Breakdown

| Class | Precision | Recall | F1 | IoU | Assessment |
|-------|-----------|--------|------|------|-----------|
| Background | 0.00 | 0.00 | 0.00 | 0.0000 | âŒ Not learned |
| Building | 0.52 | 0.92 | 0.67 | 0.5007 | âœ… Good |
| Road | 0.48 | 0.23 | 0.31 | 0.1834 | âš ï¸ Under-detected |
| Water | 0.47 | 0.49 | 0.48 | 0.3158 | ğŸŸ¡ Moderate |
| Barren | 0.22 | 0.11 | 0.15 | 0.0804 | âŒ Poor |
| Forest | 0.37 | 0.66 | 0.48 | 0.3146 | ğŸŸ¡ Moderate |
| Agriculture | 0.72 | 0.63 | 0.67 | 0.5028 | âœ… Best class |

### Analysis

ğŸ† **Best performers:**
- **Agriculture** (IoU 0.50): Largest class, well-balanced precision/recall
- **Building** (IoU 0.50): High recall (92%) but tends to over-predict

âš ï¸ **Worst performers:**
- **Background** (IoU 0.00): Not learned at all (expected with `do_reduce_labels`)
- **Barren** (IoU 0.08): Very low recall (11%), often confused with other classes
- **Road** (IoU 0.18): Low recall (23%), thin linear features are hard

ğŸ’¡ **Key observations:**
- Building has very high recall (0.92) but lower precision (0.52) â†’ over-segmentation
- Agriculture dominates the dataset (17.7M pixels) â†’ model biased toward it
- Smaller classes (barren, road) underperform â†’ class imbalance issue

---

## ğŸ“ˆ Training Log Versions

Located in `logs/`:

### DINOv3 runs (10 versions: v0â€“v9)
```
logs/dinov3_mask2former_loveda/version_0..9/
logs/dinov3_mask2former_loveda_csv/version_0..8/
```

### DINOv2 runs (12 versions: v0â€“v11)
```
logs/dinov2_mask2former_loveda/version_0..11/
```

### View with TensorBoard:
```bash
tensorboard --logdir logs/
```

---

## ğŸ¯ Potential Improvements

Based on results analysis:

1. **Class imbalance** â€” Try class-weighted loss or focal loss
2. **Barren/Road underperformance** â€” Data augmentation (rotation, flip) for thin features
3. **More epochs for DINOv3** â€” The 0.1175 mIoU suggests early stopping; DINOv2 reached 0.27 at epoch 48
4. **Higher resolution** â€” Try 1024Ã—1024 for better detection of small features (roads)
5. **Learning rate warmup** â€” Current setup jumps straight in; warmup could help stability
